{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ndgu.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"cRJV9Ol6DPlo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"outputId":"af035cd6-a1d1-4caf-a9fb-e3fe82bf00d9","executionInfo":{"status":"error","timestamp":1553085105409,"user_tz":-120,"elapsed":1402,"user":{"displayName":"Diana Noveanu","photoUrl":"https://lh5.googleusercontent.com/-SVAstMDtQbw/AAAAAAAAAAI/AAAAAAAAAHg/zzBFxH5Rs3I/s64/photo.jpg","userId":"17479844045171740159"}}},"cell_type":"code","source":["zip_id = '1ljLFxboUWZWdSK_pWf0-p3SAzEXMzuqX'\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import zipfile, os\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","if not os.path.exists('MODEL'):\n","   os.makedirs('MODEL')\n","# DOWNLOAD ZIP\n","print (\"Downloading zip file\")\n","myzip = drive.CreateFile({'id': zip_id})\n","auto = myzip.GetContentFile('screen_type.zip')\n","\n","# UNZIP ZIP\n","print (\"Uncompressing zip file\")\n","zip_ref = zipfile.ZipFile('screen_type.zip', 'r')\n","zip_ref.extractall('data/')\n","zip_ref.close()\n","##################### MOUNT YOUT GOOGLE DRIVE AS A FOLDER ######################\n","from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cf61e5a64c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzip_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1ljLFxboUWZWdSK_pWf0-p3SAzEXMzuqX'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydrive'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"iZgryEJjD2WZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9e6912fa-88e4-4844-bba9-f2477db650db","executionInfo":{"status":"ok","timestamp":1553085106981,"user_tz":-120,"elapsed":2970,"user":{"displayName":"Diana Noveanu","photoUrl":"https://lh5.googleusercontent.com/-SVAstMDtQbw/AAAAAAAAAAI/AAAAAAAAAHg/zzBFxH5Rs3I/s64/photo.jpg","userId":"17479844045171740159"}}},"cell_type":"code","source":["# Imports\n","\n","import os\n","import os.path\n","\n","import keras.callbacks\n","import matplotlib.pyplot as plt\n","import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import Sequential\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"jkDwyizyFAw0","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"EIYhVVZZFEGP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialize and load data\n","\n","weights = []\n","n_classes = 11  # \"skip\" class ignored\n","n_channels = 1 + len(weights)\n","\n","# Model \n","batch_size = 64\n","max_epochs = 20\n","period_checkpoint = 10\n","\n","# Testing\n","voting_type = 'probabilities'\n","\n","# Image formatting\n","SEED = 200\n","WIDTH = 128\n","HEIGTH = 256\n","\n","# Directory \"cleanup\"\n","SCREEN_CSV = \"../input/hmmmmm/screen_type_format2.csv\"\n","IMAGE_FOLDER = \"../input/mydata/data/data/screen_type\"\n","TRAIN_FOLDER = IMAGE_FOLDER + \"/train_images\"\n","TEST_FOLDER = IMAGE_FOLDER + \"/test_images\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"bWEBY8n5FEaT","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_screen_labels(csv, image_dir):\n","    '''\n","    Arrange the images from the file into a dictionary\n","    '''\n","    fields = ['UI.number', 'class']\n","    screen_type_csv = pd.read_csv(csv, usecols=fields,\n","                                  skipinitialspace=True).rename(index=str,\n","                                                                columns={\"UI.number\": \"UINumber\",\n","                                                                         \"class\": \"Class\"})\n","\n","    screen_type_csv = screen_type_csv.sort_values(by=['Class'])\n","    categories = np.unique(screen_type_csv['Class'].values)\n","\n","    naming_dict = {}\n","    for i in range(len(categories)):\n","        naming_dict[categories[i]] = i\n","\n","    dirs = os.listdir(image_dir)\n","    filenames = []\n","    for d in dirs:\n","        images = os.listdir(image_dir + '/' + d)\n","        filenames.append([f.split('.')[0] for f in images if f.endswith('.jpg')])\n","    filenames = filenames[0]\n","    dictionary = {}\n","    \n","    for key in filenames:\n","        info = screen_type_csv.loc[screen_type_csv['UINumber'] == int(key)].Class.values\n","        dictionary[key] = naming_dict[info[0]]\n","    return dictionary, naming_dict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qut9xzmTFEiL","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_images_labels(image_dir):\n","    dirs = os.listdir(image_dir)\n","    filenames = []\n","    for d in dirs: \n","        images = os.listdir(image_dir+'/'+d)\n","        filenames.append([f.split('.')[0] for f in images if f.endswith('.jpg')])\n","    filenames = [item for sublist in filenames for item in sublist]\n","    return filenames"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6uG4v1DyFEmZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1034},"outputId":"b05d3d0e-d367-4c59-c29f-e23160121521","executionInfo":{"status":"error","timestamp":1553085107623,"user_tz":-120,"elapsed":3605,"user":{"displayName":"Diana Noveanu","photoUrl":"https://lh5.googleusercontent.com/-SVAstMDtQbw/AAAAAAAAAAI/AAAAAAAAAHg/zzBFxH5Rs3I/s64/photo.jpg","userId":"17479844045171740159"}}},"cell_type":"code","source":["# Partition the data\n","label_dictionary, naming_dictionary = read_screen_labels(SCREEN_CSV, TRAIN_FOLDER)\n","\n","partition = {}\n","# Load partitions - currently using \"test\" as validation\n","partition['train'] = get_images_labels(TRAIN_FOLDER)\n","partition['test'] = get_images_labels(TEST_FOLDER)\n","\n","split = int(0.8 * len(partition['train']))\n","partition['validation'] = partition['train'][split:]\n","partition['train'] = partition['train'][:split]\n","\n","print(\"UIs in train:\", len(partition['train']))\n","print(\"UIs in validation:\", len(partition['validation']))\n","print(\"UIs in test:\", len(partition['test']))"],"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-194432a493c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaming_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_screen_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCREEN_CSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load partitions - currently using \"test\" as validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-b38a74ad7898>\u001b[0m in \u001b[0;36mread_screen_labels\u001b[0;34m(csv, image_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'UI.number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     screen_type_csv = pd.read_csv(csv, usecols=fields,\n\u001b[0;32m----> 7\u001b[0;31m                                   \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                                 columns={\"UI.number\": \"UINumber\",\n\u001b[1;32m      9\u001b[0m                                                                          \"class\": \"Class\"})\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/hmmmmm/screen_type_format2.csv' does not exist"]}]},{"metadata":{"id":"uqQ2m3-LFEp6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Creating the model\n","model = Sequential()\n","# Layers\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(HEIGTH, WIDTH, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(BatchNormalization())\n","model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(11, activation='softmax'))\n","\n","model.save('my_model.h5')\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PHFfVhcmFTR6","colab_type":"code","colab":{}},"cell_type":"code","source":["class LossHistory(keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","\n","    def on_batch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w0TWcg2DFWu9","colab_type":"code","colab":{}},"cell_type":"code","source":["# Model optimizer - Adam\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Fit Model\n","# TODO?\n","\n","# Data Generators\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    horizontal_flip=True,\n","    brightness_range=[0.5, 1.5],\n","    #featurewise_center=True\n","    #channel_shift_intensity=True,\n","    #featurewise_std_normalization=True,\n","    #shuffle=True\n",") \n","\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hnrm0PfxFYiQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train/Test Generators\n","train_generator = train_datagen.flow_from_directory(TRAIN_FOLDER,\n","                                                    target_size=(HEIGTH, WIDTH),\n","                                                    color_mode=\"rgb\",\n","                                                    batch_size=300,\n","                                                    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(TEST_FOLDER,\n","                                                  target_size=(HEIGTH, WIDTH),\n","                                                  color_mode=\"rgb\",\n","                                                  batch_size=300,\n","                                                  class_mode='categorical'\n","                                                  )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_24vKHdEFaDJ","colab_type":"code","colab":{}},"cell_type":"code","source":["hhistory = LossHistory()\n","history = model.fit_generator(\n","    train_generator,\n","    verbose=1,\n","    steps_per_epoch=(3507 + 877)// 300,\n","    epochs=20,\n","    validation_data=test_generator,\n","    use_multiprocessing=True,\n","    validation_steps=433 // 300,\n","    callbacks=[hhistory])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i13HQ2utFcBT","colab_type":"code","colab":{}},"cell_type":"code","source":["# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","#see loss history (numbers)\n","print(hhistory.losses)\n","model.save('my_model.h5')"],"execution_count":0,"outputs":[]}]}